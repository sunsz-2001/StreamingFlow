#!/usr/bin/env python3
"""
ODEæ¨¡å—ç‹¬ç«‹ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•åœ¨å…¶ä»–é¡¹ç›®ä¸­ä½¿ç”¨ODEæ¨¡å—ï¼Œ
åŒ…å«å®Œæ•´çš„å¯è¿è¡Œä»£ç ç¤ºä¾‹ã€‚
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os

# æ·»åŠ ODEæ¨¡å—è·¯å¾„ (å¦‚æœéœ€è¦)
# sys.path.append('/path/to/your/ode_modules')

# å¯¼å…¥ODEæ¨¡å—
try:
    from .. import NNFOwithBayesianJumps, FuturePredictionODE
    from ..configs.minimal_ode_config import create_minimal_ode_config, create_custom_ode_config
    from ..configs.config_validator import print_config_report
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from ode_modules import NNFOwithBayesianJumps, FuturePredictionODE
    from ode_modules.configs.minimal_ode_config import create_minimal_ode_config, create_custom_ode_config
    from ode_modules.configs.config_validator import print_config_report


class SimpleVideoPredictor(nn.Module):
    """
    ç®€å•çš„è§†é¢‘é¢„æµ‹æ¨¡å‹ç¤ºä¾‹
    æ¼”ç¤ºå¦‚ä½•å°†ODEæ¨¡å—é›†æˆåˆ°è‡ªå®šä¹‰æ¨¡å‹ä¸­
    """

    def __init__(self, input_channels=3, feature_channels=64, num_future_frames=4):
        super().__init__()

        print(f"ğŸ—ï¸ åˆ›å»ºè§†é¢‘é¢„æµ‹æ¨¡å‹...")
        print(f"   è¾“å…¥é€šé“: {input_channels}")
        print(f"   ç‰¹å¾é€šé“: {feature_channels}")
        print(f"   é¢„æµ‹å¸§æ•°: {num_future_frames}")

        # ç®€å•çš„ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, feature_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((32, 32))  # å›ºå®šè¾“å‡ºå°ºå¯¸
        )

        # åˆ›å»ºODEé…ç½®
        self.cfg = create_custom_ode_config(
            out_channels=feature_channels,
            latent_dim=feature_channels,
            solver="euler",
            delta_t=0.1,
            use_variable_step=False
        )

        # éªŒè¯é…ç½®
        print("\nğŸ” éªŒè¯ODEé…ç½®...")
        is_valid = print_config_report(self.cfg)
        if not is_valid:
            raise ValueError("ODEé…ç½®éªŒè¯å¤±è´¥!")

        # åˆ›å»ºODEæ¨¡å‹
        self.ode_predictor = NNFOwithBayesianJumps(
            input_size=feature_channels,
            hidden_size=feature_channels,
            cfg=self.cfg
        )

        # ç®€å•çš„è§£ç å™¨
        self.decoder = nn.Sequential(
            nn.Conv2d(feature_channels, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, input_channels, kernel_size=3, padding=1),
            nn.Sigmoid()
        )

        self.num_future_frames = num_future_frames
        print("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ!")

    def forward(self, video_sequence):
        """
        å‰å‘ä¼ æ’­

        Args:
            video_sequence: [B, T, C, H, W] è¾“å…¥è§†é¢‘åºåˆ—

        Returns:
            predictions: [B, T_future, C, H, W] é¢„æµ‹çš„æœªæ¥å¸§
            ode_loss: ODEæ¨¡å—çš„è¾…åŠ©æŸå¤±
        """
        batch_size, seq_len, channels, height, width = video_sequence.shape

        # 1. ç‰¹å¾æå–
        print(f"ğŸ“¸ å¤„ç†è§†é¢‘åºåˆ— {video_sequence.shape}")

        # å±•å¹³æ—¶åºç»´åº¦è¿›è¡Œç¼–ç 
        flat_frames = video_sequence.view(-1, channels, height, width)
        features = self.encoder(flat_frames)

        # æ¢å¤æ—¶åºç»´åº¦
        feature_channels = features.shape[1]
        feature_h, feature_w = features.shape[2], features.shape[3]
        features = features.view(batch_size, seq_len, feature_channels, feature_h, feature_w)

        print(f"ğŸ”§ æå–ç‰¹å¾ {features.shape}")

        # 2. å‡†å¤‡æ—¶é—´æˆ³
        times = torch.linspace(0, seq_len-1, seq_len, dtype=torch.float32)
        target_times = torch.linspace(seq_len, seq_len + self.num_future_frames - 1,
                                    self.num_future_frames, dtype=torch.float32)

        print(f"â° è§‚æµ‹æ—¶é—´: {times}")
        print(f"ğŸ¯ ç›®æ ‡æ—¶é—´: {target_times}")

        # 3. å‡†å¤‡ODEè¾“å…¥
        current_input = features[:, -1:, :, :, :]  # æœ€åä¸€å¸§ä½œä¸ºå½“å‰è¾“å…¥
        observations = features  # æ‰€æœ‰å¸§ä½œä¸ºè§‚æµ‹åºåˆ—

        # 4. ODEé¢„æµ‹
        print("ğŸ§  å¼€å§‹ODEé¢„æµ‹...")
        try:
            final_state, ode_loss, ode_predictions = self.ode_predictor(
                times=times,
                input=current_input,
                obs=observations,
                delta_t=0.1,
                T=target_times
            )

            print(f"âœ… ODEé¢„æµ‹å®Œæˆ! è¾“å‡ºå½¢çŠ¶: {ode_predictions.shape}")
            print(f"ğŸ“Š ODEæŸå¤±: {ode_loss}")

        except Exception as e:
            print(f"âŒ ODEé¢„æµ‹å¤±è´¥: {e}")
            print("ğŸ”„ ä½¿ç”¨é›¶é¢„æµ‹ä½œä¸ºåå¤‡æ–¹æ¡ˆ")
            ode_predictions = torch.zeros(batch_size, len(target_times),
                                        feature_channels, feature_h, feature_w)
            ode_loss = 0.0

        # 5. è§£ç åˆ°åƒç´ ç©ºé—´
        print("ğŸ¨ è§£ç é¢„æµ‹ç»“æœ...")
        batch_future, future_len = ode_predictions.shape[:2]
        flat_predictions = ode_predictions.view(-1, feature_channels, feature_h, feature_w)

        # ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        upsampled = nn.functional.interpolate(flat_predictions, size=(height, width),
                                            mode='bilinear', align_corners=False)
        decoded_frames = self.decoder(upsampled)

        # æ¢å¤æ—¶åºç»´åº¦
        predicted_frames = decoded_frames.view(batch_future, future_len, channels, height, width)

        print(f"ğŸ¬ æœ€ç»ˆé¢„æµ‹å½¢çŠ¶: {predicted_frames.shape}")

        return predicted_frames, ode_loss


def run_basic_example():
    """è¿è¡ŒåŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸš€ åŸºç¡€ODEæ¨¡å—ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)

    # 1. åˆ›å»ºé…ç½®
    cfg = create_minimal_ode_config()

    # 2. åˆ›å»ºæ¨¡å‹
    model = NNFOwithBayesianJumps(
        input_size=64,
        hidden_size=64,
        cfg=cfg
    )

    print("âœ… ODEæ¨¡å‹åˆ›å»ºæˆåŠŸ!")

    # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
    batch_size = 2
    current_input = torch.randn(batch_size, 1, 64, 32, 32)
    observations = torch.randn(batch_size, 3, 64, 32, 32)
    times = torch.tensor([0.0, 0.5, 1.0])
    target_times = torch.tensor([1.5, 2.0, 2.5])

    print(f"ğŸ“Š è¾“å…¥æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"   å½“å‰è¾“å…¥: {current_input.shape}")
    print(f"   è§‚æµ‹åºåˆ—: {observations.shape}")
    print(f"   è§‚æµ‹æ—¶é—´: {times}")
    print(f"   ç›®æ ‡æ—¶é—´: {target_times}")

    # 4. å‰å‘ä¼ æ’­
    print("\nğŸ§  æ‰§è¡Œå‰å‘ä¼ æ’­...")

    try:
        with torch.no_grad():  # æ¨ç†æ¨¡å¼
            final_state, loss, predictions = model(
                times=times,
                input=current_input,
                obs=observations,
                delta_t=0.1,
                T=target_times
            )

        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"ğŸ“ˆ é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")
        print(f"ğŸ“Š æŸå¤±å€¼: {loss}")
        print(f"ğŸ¯ é¢„æµ‹ç»Ÿè®¡:")
        print(f"   å‡å€¼: {predictions.mean().item():.4f}")
        print(f"   æ ‡å‡†å·®: {predictions.std().item():.4f}")
        print(f"   æœ€å°å€¼: {predictions.min().item():.4f}")
        print(f"   æœ€å¤§å€¼: {predictions.max().item():.4f}")

        return True

    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_video_prediction_example():
    """è¿è¡Œè§†é¢‘é¢„æµ‹ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸ¬ è§†é¢‘é¢„æµ‹æ¨¡å‹ç¤ºä¾‹")
    print("=" * 60)

    # 1. åˆ›å»ºè§†é¢‘é¢„æµ‹æ¨¡å‹
    video_model = SimpleVideoPredictor(
        input_channels=3,
        feature_channels=32,  # ä½¿ç”¨è¾ƒå°çš„é€šé“æ•°ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        num_future_frames=3
    )

    # 2. å‡†å¤‡è§†é¢‘æ•°æ®
    batch_size = 1  # å‡å°‘batch size
    seq_len = 4
    height, width = 64, 64  # è¾ƒå°çš„åˆ†è¾¨ç‡

    print(f"\nğŸ“¹ å‡†å¤‡è§†é¢‘æ•°æ®:")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   åºåˆ—é•¿åº¦: {seq_len}")
    print(f"   åˆ†è¾¨ç‡: {height}x{width}")

    # æ¨¡æ‹Ÿè§†é¢‘åºåˆ— (ä¾‹å¦‚ç§»åŠ¨çš„æ–¹å—)
    video_frames = []
    for t in range(seq_len):
        frame = torch.zeros(batch_size, 3, height, width)
        # åˆ›å»ºç§»åŠ¨çš„æ–¹å—
        start_x = 10 + t * 5
        start_y = 10 + t * 3
        frame[:, :, start_y:start_y+10, start_x:start_x+10] = 0.8
        video_frames.append(frame)

    video_sequence = torch.stack(video_frames, dim=1)
    print(f"âœ… è§†é¢‘æ•°æ®å½¢çŠ¶: {video_sequence.shape}")

    # 3. é¢„æµ‹
    print("\nğŸš€ å¼€å§‹è§†é¢‘é¢„æµ‹...")

    try:
        with torch.no_grad():
            predicted_frames, ode_loss = video_model(video_sequence)

        print("âœ… è§†é¢‘é¢„æµ‹æˆåŠŸ!")
        print(f"ğŸ¯ é¢„æµ‹å¸§å½¢çŠ¶: {predicted_frames.shape}")
        print(f"ğŸ“Š ODEæŸå¤±: {ode_loss}")

        # ç®€å•çš„è´¨é‡è¯„ä¼°
        input_mean = video_sequence.mean()
        pred_mean = predicted_frames.mean()
        print(f"ğŸ“ˆ è¾“å…¥å‡å€¼: {input_mean:.4f}")
        print(f"ğŸ“ˆ é¢„æµ‹å‡å€¼: {pred_mean:.4f}")
        print(f"ğŸ“ˆ å·®å¼‚: {abs(input_mean - pred_mean):.4f}")

        return True

    except Exception as e:
        print(f"âŒ è§†é¢‘é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_performance_test():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("âš¡ æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    import time

    # æµ‹è¯•ä¸åŒé…ç½®çš„æ€§èƒ½
    configs = [
        ("è½»é‡çº§", create_custom_ode_config(out_channels=32, latent_dim=32, delta_t=0.2)),
        ("æ ‡å‡†", create_custom_ode_config(out_channels=64, latent_dim=64, delta_t=0.1)),
        ("é«˜ç²¾åº¦", create_custom_ode_config(out_channels=64, latent_dim=64, solver="midpoint", delta_t=0.05)),
    ]

    for config_name, cfg in configs:
        print(f"\nğŸ§ª æµ‹è¯• {config_name} é…ç½®...")

        try:
            model = NNFOwithBayesianJumps(cfg.MODEL.ENCODER.OUT_CHANNELS,
                                        cfg.MODEL.DISTRIBUTION.LATENT_DIM, cfg)

            # å‡†å¤‡æ•°æ®
            batch_size = 1
            channels = cfg.MODEL.ENCODER.OUT_CHANNELS
            current_input = torch.randn(batch_size, 1, channels, 16, 16)
            observations = torch.randn(batch_size, 3, channels, 16, 16)
            times = torch.tensor([0.0, 0.5, 1.0])
            target_times = torch.tensor([1.5, 2.0])

            # é¢„çƒ­
            with torch.no_grad():
                _ = model(times, current_input, observations, cfg.MODEL.FUTURE_PRED.DELTA_T, target_times)

            # è®¡æ—¶
            num_runs = 10
            start_time = time.time()

            for _ in range(num_runs):
                with torch.no_grad():
                    _ = model(times, current_input, observations, cfg.MODEL.FUTURE_PRED.DELTA_T, target_times)

            end_time = time.time()
            avg_time = (end_time - start_time) / num_runs

            print(f"âœ… {config_name} å¹³å‡æ¨ç†æ—¶é—´: {avg_time*1000:.2f}ms")

        except Exception as e:
            print(f"âŒ {config_name} æµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ODEæ¨¡å—é›†æˆç¤ºä¾‹")
    print("ä½œè€…: Claude Code")
    print("ç‰ˆæœ¬: 1.0")
    print("")

    # è®¾ç½®éšæœºç§å­ä»¥è·å¾—å¯é‡å¤çš„ç»“æœ
    torch.manual_seed(42)
    np.random.seed(42)

    # æ£€æŸ¥è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    if device.type == 'cuda':
        print(f"   GPU: {torch.cuda.get_device_name()}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")

    success_count = 0
    total_tests = 3

    # è¿è¡Œç¤ºä¾‹
    try:
        # 1. åŸºç¡€ç¤ºä¾‹
        if run_basic_example():
            success_count += 1

        # 2. è§†é¢‘é¢„æµ‹ç¤ºä¾‹
        if run_video_prediction_example():
            success_count += 1

        # 3. æ€§èƒ½æµ‹è¯•
        try:
            run_performance_test()
            success_count += 1
        except Exception as e:
            print(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")

    except Exception as e:
        print(f"\nğŸ’¥ æœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {success_count}/{total_tests}")
    print(f"âŒ å¤±è´¥: {total_tests - success_count}/{total_tests}")

    if success_count == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ODEæ¨¡å—å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")

    print("\nğŸ“š æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ:")
    print("   - INTEGRATION_GUIDE.md: è¯¦ç»†é›†æˆæŒ‡å—")
    print("   - configs/README.md: é…ç½®å‚æ•°è¯´æ˜")
    print("   - tests/: å®Œæ•´æµ‹è¯•å¥—ä»¶")


if __name__ == "__main__":
    main()